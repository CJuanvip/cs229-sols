import numpy as np
import homework1_5b as hm1b


TRAINING_DATA = 'quasar_train.csv'
TESTING_DATA  = 'quasar_test.csv'
RIGHT_FREQ = 1300
LEFT_FREQ  = 1200


def load_csv(file):
    return np.loadtxt(file, delimiter=',')


def load_data(training_data_file=TRAINING_DATA, testing_data_file=TESTING_DATA):
    data_training = load_csv(training_data_file)
    data_testing = load_csv(testing_data_file)
    
    features_training = data_training[0]
    features_testing = data_testing[0]
    
    assert(np.array_equal(features_training, features_testing))
    
    features = features_training
    data_set_tr = data_training[1:]
    data_set_te = data_testing[1:]
    
    return features, data_set_tr, data_set_te

def estimate(tau, features, training):
    w_tau = hm1b.weightM(tau)
    return SpectrumModel(training, features, w_tau)


def estimates(taus, features, training):
    models = {}
    for tau in taus:
        models[tau] = estimate(tau, features, training)
        
    return models

def join_intercept(mat):
    ones = np.ones(((len(mat), 1)))

    return np.concatenate((ones, mat), axis=1)


class SpectrumModel():
    """
    The SpectrumModel type packs the smooths of each training example in a data set
    of light spectra together so the entire model can be evaluated conveniently.
    """
    def __init__(self, data_set, features, weight_matrix):
        self._data_set = data_set
        self._features = join_intercept(features.reshape(len(features), 1))

        spectrums = {}
        for i in range(0, len(data_set)):
            W_i = weight_matrix(self._features)
            y_i = data_set[i]
            spectrums[i] = hm1b.LWLRModel(W_i, self._features, y_i)

        self._spectrums = spectrums

    def evaluate(self, x):
        """
        Evaluate takes an input vector of wavelengths X, and returns a matrix of 
        estimates such that each row i is a function generated by the smooth of the spectrum from 
        the ith training example. Each column j is the estimate of relative flux by estimator
        i for input value j.
        """
        # First try treating x as a vector. If this succeeds we are evaluating pointwise.
        rows = len(self._spectrums)
        try:
            cols = len(x)
        except:
            # Otherwise, try treating it as a scalar.
            cols = 1

        results = np.zeros((rows, cols))
        for i in range(0, rows):
            results[i] = self._spectrums[i](x)

        return results
 
    @property 
    def spectrums(self):
        return self._spectrums

    def __call__(self, x):
        return self.evaluate(x)


def d(f1, f2, z):
    diff = f1(z) - f2(z)
    return diff.T.dot(diff)

def d_evaled(fs, f):
    try:
        rows = len(fs)
    except:
        rows = 1
    
    v = np.zeros(len(fs))
    for i in range(rows):
        diff = fs[i] - f
        v[i] = diff.T.dot(diff)
    
    return v

ker = np.vectorize(lambda t: max(1-t, 0))

def right(f, features):
    r = np.where(features == RIGHT_FREQ)
    assert(r)
    return f[:,r[0][0]:]

    
def left(f, features):
    l = np.where(features == RIGHT_FREQ)
    assert(l)
    return f[:,:l[0][0]]


def h(gs, f, features):
    v = np.zeros(len(gs))
    for i in range(len(gs)):
        v[i] = d(gs[i], f, features)
        
    return np.max(v)


def h_evaled(gs, f):
    v = d_evaled(gs, f)
    return np.max(v)


def neighbk(k, fs, f_right):    
    assert(k <= len(fs))
    costs = d_evaled(fs, f_right)
    # Get the indices of the k lowest cost functions by index.
    k_indices = costs.argsort()[:k]
        
    #return fs[k_indices]
    return k_indices

def neighbk_vecs(k, fs, f_right):
    return fs[neighbk(k, fs, f_right)]


class SpectrumEstimator():
    def __init__(self, m, m_eval_right, f_right, features):
        self.features = features
        self.f_right = f_right
        self.m = m
        self.m_eval_right = m_eval_right
        self.d_max = h_evaled(m_eval_right, f_right)
        self.ker_coefs = ker(d_evaled(m_eval_right, f_right) / self.d_max)
        self.ker_sum = np.sum(self.ker_coefs[neighbk(3, m_eval_right, f_right)])
        # The shape of m_eval_left will be smaller because we are evaluating 
        # on a subset of the data set.
        self.series_coef_indices = neighbk(3, self.m_eval_right, self.f_right)
        
    def evaluate(self, x):
        ker_coefs = self.ker_coefs[self.series_coef_indices]
        f_lefts = left(self.m(x), self.features)[self.series_coef_indices]
        return np.sum((ker_coefs * f_lefts.T).T, axis=0) / self.ker_sum
        
    def __call__(self, x):
        return self.evaluate(x)
