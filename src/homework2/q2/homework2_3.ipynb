{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2 Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import read_matrix as rm\n",
    "import nb_train\n",
    "import nb_test\n",
    "import svm_train\n",
    "import svm_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3.a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first machine learning algorithm for classifying spam emails is the Naive Bayes model. First we trained the model using the ```MATRIX.TRAIN``` data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = rm.read_data('spam_data/MATRIX.TRAIN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_model = nb_train.train(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we ran the model against the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test = rm.read_data('spam_data/MATRIX.TEST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_predictions = nb_test.test(nb_model, df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is the testing error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = df_test.iloc[:,0]\n",
    "nb_error = nb_test.compute_error(y, nb_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB Test error: 0.01625\n"
     ]
    }
   ],
   "source": [
    "print('NB Test error: {}'.format(nb_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3.b."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The five most indicative words of a spam message are the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = nb_test.k_most_indicative_words(5, nb_model.to_dataframe().iloc[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 5 most spam-worthy words are: ['httpaddr', 'spam', 'unsubscrib', 'ebai', 'valet']\n"
     ]
    }
   ],
   "source": [
    "print('The {} most spam-worthy words are: {}'.format(len(words), words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3.c."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the convergence properties of the Naive Bayes classifier on the email data set, it needs to be run on different training set sizes. Here we use six different sized training sets to see how the error rate progresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_set_files = {\n",
    "        50   : 'spam_data/MATRIX.TRAIN.50', \n",
    "        100  : 'spam_data/MATRIX.TRAIN.100', \n",
    "        200  : 'spam_data/MATRIX.TRAIN.200', \n",
    "        400  : 'spam_data/MATRIX.TRAIN.400', \n",
    "        800  : 'spam_data/MATRIX.TRAIN.800', \n",
    "        1400 : 'spam_data/MATRIX.TRAIN.1400'\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimate the models and compute the errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_models = {}\n",
    "for size, filename in training_set_files.items():\n",
    "    df_next = rm.read_data(filename)\n",
    "    m = nb_train.train(df_next)\n",
    "    nb_models[size] = m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_errors = {}\n",
    "for size, model in nb_models.items():\n",
    "    guessed_y = nb_test.test(model, df_test)\n",
    "    err = nb_test.compute_error(y, guessed_y)\n",
    "    nb_errors[size] = err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting errors are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes\n",
      "size: 50; error: 0.13125\n",
      "size: 100; error: 0.04\n",
      "size: 200; error: 0.02625\n",
      "size: 400; error: 0.02\n",
      "size: 800; error: 0.01625\n",
      "size: 1400; error: 0.01625\n"
     ]
    }
   ],
   "source": [
    "print('Naive Bayes')\n",
    "for size, error in nb_errors.items():\n",
    "    print('size: {}; error: {}'.format(size, error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the training set size increases, the error rate for the Naive Bayes classifier decreases. It converges above a training set size of about 1000 emails."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3.d."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second model used to classify the emails is a support vector machine. As in part (a), we train the SVM model using the ```MATRIX.TRAIN``` data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tau = 8\n",
    "max_iters = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = svm_train.train(df_train, tau, max_iters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we run the trained SVM model against the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "svm_predictions = svm_test.test(svm_model, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800,)\n"
     ]
    }
   ],
   "source": [
    "print(svm_predictions.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The testing error is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytest = 2 * df_test.iloc[:,0].as_matrix() - 1\n",
    "svm_error = svm_test.compute_error(ytest, svm_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Test Error: 0.0\n"
     ]
    }
   ],
   "source": [
    "print('SVM Test Error: {}'.format(svm_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the varying sized training sets, we estimate an svm model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_models = {}\n",
    "for size, filename in training_set_files.items():\n",
    "    df_next = rm.read_data(filename)\n",
    "    m = svm_train.train(df_next, tau, max_iters)\n",
    "    svm_models[size] = m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we compute the errors for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm_errors = {}\n",
    "for size, model in svm_models.items():\n",
    "    guessed_y = svm_test.test(model, df_test)\n",
    "    err = svm_test.compute_error(ytest, guessed_y)\n",
    "    svm_errors[size] = err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting errors are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine\n",
      "size: 50; error: 0.50125\n",
      "size: 100; error: 0.5175\n",
      "size: 200; error: 0.50125\n",
      "size: 400; error: 0.5025\n",
      "size: 800; error: 0.5\n",
      "size: 1400; error: 0.5\n"
     ]
    }
   ],
   "source": [
    "print('Support Vector Machine')\n",
    "for size, error in svm_errors.items():\n",
    "    print('size: {}; error: {}'.format(size, error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3.e."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this data set, the SVM is a much better classifier than the Naive Bayes classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
